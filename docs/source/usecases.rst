Use Cases
=========


Benchmark social designs
------------------------

*Suppose you were assembling a team of humans, or an AI, or a 
collaboration between humans and AI to play a real-world game, such as 
stocktrading, diplomacy, policymaking, or to compete in business.*
Previous simulations find that existing social designs retard social 
progress `by 3 to 25 times <https://figshare.
com/articles/dataset/Varieties_of_Elitism/7052264>`_, but how can you test
alternatives? 

With redscience, you can benchmark different team-sizes, personality 
ratios, curriculum ratios, and collaboration techniques (e.g. elitism vs 
pure democracy) on specific games or `to face the unexpected <Olympics>`_. 
These may be considered pre-clinical trials to increase the success-rates
of other tests (like testing on animal subjects before testing on humans).

For example,   

#. Identify the most comprehensive :doc:`Olympics <tournament>`_ via the **Comparison Tab**, 
   identify the top team for that Olympics via its :doc:`leaderboard <game>`, 
   and identify an essential member of that team using its **Members Tab**.
#. :doc:`Clone the team <playerfactory>` to create a new one, and slightly 
   modify one dimension of the personality of the cloned essential member 
   (e.g. make the clone less extreme). 
#. Run an Olympic :doc:`tournament <tournament>` which includes both the 
   current champion and its modified clone. Does the modified clone 
   outperform its parent, or does the parent make the extreme personality of 
   that team-member into a strength?

.. Note:: The most comprehensive Olympics will include cooperative games 
  (like the *Public Goods game*), alliance games (like *Risk*), deception 
  games (like *Hide and Seek*), and probabilistic games (like *Poker*), 
  as well as traditionally competitive games (like *Chess*), so this approach 
  hedges against the potential for any real-world game to 
  shift in any of these directions.

Anticipate security exploits 
----------------------------

*Suppose you were a developer assigned to deploy a new AI to the real world 
or a parent/teacher trying to help a new human find their place in society.*
You's want to know in advance about any exploits to which that AI or person is 
vulnerable, so you can protect them:

#. Build the AI in redscience or have the human 
   :doc:`establish an account <player>`. Have this player play a diverse variety
   of :doc:`games <games>` against the reigning champions.
#. Look at the player’s **Favoritism Tab** to identify tools that 
   consistently perform better against that player than against other players 
   of the same skill-level.
#. Look at the favoritism stats for those tools to find other players whom
   they exploit in the same way. What do the victims have in common 
   (e.g. Risk-aversion? Risk-proclivity?)
#. Browse the **Favoritism Tab** to find games in which that 
   vulnerability does not manifest (i.e. games that are "safe" for the player).
   What do they have in common (and what real-world games share that commonality)?
#. Regarding "unsafe" games, compare victims’ favoritism stats with different 
   forms of :doc:`tool-use <playerfactory>`. Which forms of tool use (if any) 
   are sufficient to neutralize the victims' handicap? Juries, news channels, 
   doctors, religious teachers, and algorithms encoded in scripture and law are 
   all examples of real-world tools that can help someone overcome a vulnerability
   and make more effective decisions. These experiments help identify situations 
   in which using such tools may be most wise, and forms in which they could 
   protect with minimal interference to agency.

.. Warning:: Patterns in the ways you can be defeated in various games 
  constitute private information (like personality test scores, 
  standardized test scores, or the results of genetic tests), so use 
  an account that cannot be traced to you whenever playing large numbers
  of games without AI assistance!

Discover new dimensions of intelligence
---------------------------------------

*Suppose you loved someone someone so much that you wanted to leave a valuable 
legacy to their children and to the generations that follow. More than build an
empire, you want to advance the standard of quality so that any "better" 
empire would be building on your legacy.* What legacy could be more enriching 
that granting a culture its first awareness of music, empathy, tool-use, 
exploration or other not-yet-named dimension of intelligence? 

Intelligence is measured in terms of the kinds of games which one being 
wins over another, so every dimension of intelligence can be expressed as a 
kind of game (e.g. games that test empathy by requiring players to collaborate
with players of different skill-level and experience). The most comprehensive 
:doc:`Olympics <tournament>`_ would test every dimension of intelligence, so creating more 
comprehensive Olympics is like expanding the Periodic Table of the Elements:

#. Identify the most comprehensive Olympics via the **Comparison Tab**
#. Use the **Comparison Tab** on the events of that Olympics to identify an 
   essential event in it, then fine-tune tools for that specific event (see 
   `Benchmark social designs`_). 
#. Contrast :doc:`the best tools for that event <game>` to the best tools 
   for other events to understand which :doc:`tools’ biases <playerfactory>` 
   are particularly advantageous for that event.
#. :doc:`Clone the event and tweak its design <gamefactory>` to make those 
   biases even more advantageous.
#. Use the **Comparison Tab** to confirm that swapping-in the new event makes 
   the Olympics more comprehensive.  

Elevate reality above experimentation
-------------------------------------

*Suppose our society were divided by competing systems of social norms.* For
example, the best strategy in the *Volunteer* game depends upon prevailing 
social norms which happen to correspond to the real-world norms of "turn-taking"
vs "caste system" (which sometimes manifests as racial discrimination). 
redscience might provide a better way to resolve disagreement about which norms
to choose: 

#. Copy the top-ranked *AI* for the *Volunteer* :doc:`game <game>` to a new 
   *Universe* (but :doc:`do not copy its curriculum <playerfactory>`). Play a 
   turn-taking strategy against it (i.e. “You volunteered last time, now it’s my 
   turn”) and confirm that it learns to take turns. Make several copies of that 
   *AI* in that *Universe*.
#. Similarly create a second private *Universe* in which you train all *AI* 
   to play *Volunteer* via caste (i.e. whoever got the better deal last time 
   gets it again). Copy in an *AI* from the turn-taking *Universe* (retaining
   its turn-taking experience) and confirm that it switches to the caste
   strategy. Copy an *AI* to the turn-taking *Universe* (retaining experience) 
   and confirm that it switches to turn-taking.
#. Create a third private *Universe* composed equal numbers of players from the  
   first two *Universes*. Which norm survives a *Volunteer* :doc:`tournament <tournament>`?
   Similarly test other population ratios to find the minimum ratio for the 
   other norm to survive. 

If we couldn’t run these experiments to our satisfaction in redscience, 
would we be doomed to spend our real lives serving as the subjects of 
such experiments (i.e. as pawns in a war between competing systems of 
norms)?

Empower social science and computer science students to explore
---------------------------------------------------------------

*Suppose you were a social science or computer science teacher*. It's one thing
to expose students to new ideas, but another thing to empower students to test 
those ideas for themselves. Although redscience is designed to be accessible at
the secondary-education level, it is just as relevant in post-secondary education.

* A social science teacher could assign students to `Benchmark social designs`_,
  `Anticipate security exploits`_, or `Elevate reality above experimentation`_

* A computer science teacher could assign students to `Anticipate security exploits`_
  (so they are aware of the security vulnerabilities of AI) and to 
  `build their own redscience <curriculum>`_
