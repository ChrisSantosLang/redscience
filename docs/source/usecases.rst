Use Cases
=========


1. **Benchmark social designs (e.g. for an AI or team of humans to make 
   policies or trade stocks).** Rather than serve as pawns in battles for 
   power, establish authority via simulations. You can benchmark different 
   team-sizes, personality ratios, curriculum ratios, and collaboration 
   techniques (e.g. elitism vs pure democracy) on specific games or 
   compare adaptability by benchmarking on diverse combinations of events 
   never encountered before (`rougher previous simulations <https://figshare.
   com/articles/dataset/Varieties_of_Elitism/7052264>`_ estimate opportunity 
   to advance the current rate of social progress by 3 to 25 times!). For 
   example,   

   #. Identify the most comprehensive olympics via the comparison page, 
      identify the top team for that olympics via its leaderboard, and 
      identify an essential member of that team using its Members tab.
   #. Clone the team to create a new contender, and slightly modify one 
      dimension of the personality of the cloned essential member (e.g. make 
      the clone less extreme)
   #. Copy the parent’s training schedule to the clone and execute the training
   #. Run an olympic tournament which includes both the current champion and 
      its modified clone. Does the modified clone outperform its parent, or 
      does the parent turn the extreme personality of that team-member into a 
      strength?

   Note that the most comprehensive olympics will include cooperative games 
   (like the *Public Goods game*), alliance games (like *Risk*), deception 
   games (like *Hide and Seek*), and probabilistic games (like *Poker*), 
   as well as traditionally competitive games (like *Chess*), so this approach 
   hedges against the potential for any real-world game (e.g. stock trading) to 
   shift in any of these directions.

2. **Find the skills of the future.** We create more comprehensive olympics by 
   adding events that make different demands on players. For example:

   #. Identify the most comprehensive olympics via the comparison page
   #. Use the comparison page to identify an event that makes unique demands, 
      then fine-tune tools for that specific event (see #1 above). 
   #. Contrast the best tools for that event to the best tools for other 
      events to understand which tools’ biases are particularly advantageous 
      for that event.
   #. Clone the event and tweak its design to make one of those biases even 
      more advantageous.
   #. Use the comparison page to confirm that the new event is even more 
      unique, and that a new Olympics including that event is now the most 
      comprehensive. 

3. **Discover how you or any given personality (e.g. of a proposed AI) are 
   vulnerable to exploitation.**

   #. Look at a player’s “Favoritism” tab to identify tools that perform 
      better against that player than against other players of its same 
      skill-level 
   #. Look at the Favoritism stats for those tools to find other players they 
      exploit in the same way. What do the victims have in common? (As 
      examples, depending on the game, a tool might exploit risk-aversion or 
      willingness to gamble.)
   #. Browse the Favoritism tab to find games in which that vulnerability 
      does not manifest.
   #. Compare victims’ Favoritism stats for playing alone vs using tools. 
      Which forms of tool use (if any) are sufficient to neutralize the 
      vulnerability (i.e. review, debate, delegation)? What is the difference 
      between using a tool to protect oneself from exploitation vs. 
      relinquishing freedom to that tool (e.g. To what extent is freedson 
      relinquished when taking advice from a jury, a news channel, a doctor, 
      a religious teacher, or an algorithm encoded in a scripture or law, 
      etc.)?

.. warning:: This can be humbling! But humility might come in handy...

4. **Elevate reality above experimentation.** For example, the best strategy 
   in the *Volunteer* game depends upon prevailing social norms: 

   #. Create a private universe in which you train all tools to play 
      Volunteer via turn-taking (i.e. “You volunteered last time, now it’s 
      my turn”). Confirm that the social norms of that universe push all 
      tools towards turn-taking.
   #. Create a separate private universe in which you train all tools to 
      play Volunteer via caste (i.e. whoever got the better deal last time 
      gets it again). Confirm that the social norms of that universe push 
      all tools towards a caste system (i.e. turn-taking backfires). 
   #. Create a third private universe composed half of players copied from 
      the turn-taking universe and half of players copied from the caste 
      universe. Which norm survives a Volunteer tournament? Similarly test 
      other population ratios to find the minimum ratio for the other norm 
      to survive. 

   If we couldn’t run these experiments to our satisfaction in redscience, 
   would we be doomed to spend our real lives serving as the subjects of 
   such experiments (i.e. as pawns in a war between competing systems of 
   norms)? If the most-defensible norm is one you considered morally wrong, 
   does the evidence that “resistance is futile” make you reexamine the 
   basis for that moral belief?
